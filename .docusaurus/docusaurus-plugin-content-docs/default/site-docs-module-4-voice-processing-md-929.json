{
  "unversionedId": "module4/voice-processing",
  "id": "module4/voice-processing",
  "title": "Voice and Language Processing in VLA Systems — AI in Motion",
  "description": "Voice and language processing form a critical component of Vision-Language-Action (VLA) systems, enabling robots to understand human instructions, engage in dialogue, and interpret semantic meaning from spoken or written commands. This module explores how language understanding integrates with visual perception and action execution to create more intuitive human-robot interactions.",
  "source": "@site/docs/module4/voice-processing.md",
  "sourceDirName": "module4",
  "slug": "/module4/voice-processing",
  "permalink": "/ai-in-motion/docs/module4/voice-processing",
  "draft": false,
  "editUrl": "https://github.com/your-username/ai-in-motion/tree/main/docs/module4/voice-processing.md",
  "tags": [],
  "version": "current",
  "frontMatter": {
    "title": "Voice and Language Processing in VLA Systems — AI in Motion"
  },
  "sidebar": "tutorialSidebar",
  "previous": {
    "title": "Introduction to Vision-Language-Action (VLA) — AI in Motion",
    "permalink": "/ai-in-motion/docs/module4/intro"
  },
  "next": {
    "title": "Cognitive Planning in VLA Systems — AI in Motion",
    "permalink": "/ai-in-motion/docs/module4/cognitive-planning"
  }
}